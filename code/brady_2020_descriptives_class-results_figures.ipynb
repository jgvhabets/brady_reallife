{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import itertools\n",
    "from itertools import compress\n",
    "import pdb\n",
    "\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "from os.path import join\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import scipy\n",
    "from scipy.signal import welch, decimate, periodogram, find_peaks\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, mannwhitneyu, spearmanr, ranksums, ttest_ind, f_oneway\n",
    "from scipy.ndimage.filters import uniform_filter1d\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "from statistics import mode\n",
    "import math  \n",
    "import random \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler , MinMaxScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_val_predict, cross_val_score, KFold, train_test_split, StratifiedKFold, GridSearchCV \n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, auc, f1_score, precision_recall_curve\n",
    "from sklearn.manifold import MDS\n",
    "import seaborn as sns\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas: 1.1.3\n",
      "Numpy: 1.19.1\n",
      "SciPy: 1.5.2\n"
     ]
    }
   ],
   "source": [
    "# # Version check of used packages\n",
    "print('Pandas:',pd.__version__)\n",
    "print('Numpy:',np.__version__)\n",
    "print('SciPy:',scipy.__version__)\n",
    "# Pandas: 1.1.3\n",
    "# Numpy: 1.19.1\n",
    "# SciPy: 1.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path and working directory defined as /Users/jeroenhabets/Research/pd_sensors/brady_reallife\n"
     ]
    }
   ],
   "source": [
    "# define path, working directory which contains filtered accelerometer files\n",
    "\n",
    "# path=\"/Users/jeroenhabets/Desktop/radboud data/data/\"\n",
    "notebook_path = os.getcwd()\n",
    "path = os.path.dirname(notebook_path)\n",
    "# images_path = \"/Users/jeroenhabets/Starr Lab Dropbox/jeroen habets/PHD werkmap/UCSF time/Sensor-project/analysis images/\"\n",
    "\n",
    "os.chdir(path)\n",
    "print('Path and working directory defined as %s' %path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-life ON- vs OFF-bradykinesia detection using a wrist-accelerometer  - Patient population description and classification results (incl. significance and clinical correlations)\n",
    "\n",
    "Prep: Loading in extracted accelerometer bradykinesia features (one value/ 60 seconds, medState 0 is pre-medication, 1 is post-medication), and outcomes from classification analyses.\n",
    "\n",
    "Part 1: Descriptive statistics of population.\n",
    "\n",
    "Part 2: Analyzing population for differences in medication-states based on 4 main features, using MANOVA + post-hoc ANOVA analyses.\n",
    "\n",
    "Part 3a: Comparing classification results with barplots (varying models and data inclusion approaches).\n",
    "\n",
    "Part 3b: Comparing classification results with equivalent plots.\n",
    "\n",
    "Part 4: Correlating predictive performance with clinical characteristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: Load clinical info, features, and classification reults\n",
    "Previsouly filtered data is loaded in to dataframes per patient-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadUPDRSscores():\n",
    "    '''\n",
    "    Input:\n",
    "    Load in existing updrsScores table\n",
    "    \n",
    "    Returns:\n",
    "    - updrsScores: dataframe with clinical scores of all patients\n",
    "    \n",
    "    PM: Differences are calculated OFF minus ON, which means clinical IMPROVEMENT (decrease in UPDRS in ON\n",
    "    compared to OFF) results in POSITIVE diff-scores. (A negative diff-score means a clinical worsening \n",
    "    with a higher UPDRS-score in ON compared to OFF) \n",
    "    \n",
    "    '''\n",
    "    # Read in updrs file\n",
    "    updrsScores = pd.read_csv(os.path.join(path,'data','updrsScores.csv'))\n",
    "    # convert int to strings for PtId's\n",
    "    updrsScores['PtId'] = updrsScores['PtId'].astype(str)\n",
    "    # add missing zeros in front of PtId\n",
    "    for row in np.arange(updrsScores.shape[0]):\n",
    "        updrsScores.at[row,'PtId'] = updrsScores.loc[row]['Record Id'][3:]\n",
    "    del(updrsScores['Record Id'])\n",
    "    updrsScores = updrsScores.set_index('PtId')\n",
    "    \n",
    "    # create list for ON and OFF for subscore-lists\n",
    "    OFF_sublists = {\n",
    "        'leftHandBradyOFF': ['OFF_UPDRS_3_3c','OFF_UPDRS_3_4b','OFF_UPDRS_3_5b','OFF_UPDRS_3_6b',],\n",
    "        'rightHandBradyOFF': ['OFF_UPDRS_3_3b','OFF_UPDRS_3_4a','OFF_UPDRS_3_5a','OFF_UPDRS_3_6a',],\n",
    "        'bradyBodyOFF': ['OFF_UPDRS_3_14'],\n",
    "        'leftHandTremorOFF': ['OFF_UPDRS_3_15b','OFF_UPDRS_3_16b','OFF_UPDRS_3_17b',],\n",
    "        'rightHandTremorOFF': ['OFF_UPDRS_3_15a','OFF_UPDRS_3_16a','OFF_UPDRS_3_17a',],\n",
    "        'legsOFF': ['OFF_UPDRS_3_7a','OFF_UPDRS_3_7b','OFF_UPDRS_3_8a','OFF_UPDRS_3_8b'],\n",
    "        'gaitOFF': ['OFF_UPDRS_3_9','OFF_UPDRS_3_10','OFF_UPDRS_3_11'],\n",
    "        'postureOFF': ['OFF_UPDRS_3_12','OFF_UPDRS_3_13'],\n",
    "        'facialOFF': ['OFF_UPDRS_3_1','OFF_UPDRS_3_2',]}\n",
    "    \n",
    "    ON_sublists = {\n",
    "        'leftHandBradyON': ['ON_UPDRS_3_3c', 'ON_UPDRS_3_4b','ON_UPDRS_3_5b','ON_UPDRS_3_6b',],\n",
    "        'rightHandBradyON': ['ON_UPDRS_3_3b','ON_UPDRS_3_4a','ON_UPDRS_3_5a','ON_UPDRS_3_6a',],\n",
    "        'bradyBodyON': ['ON_UPDRS_3_14'],\n",
    "        'leftHandTremorON': ['ON_UPDRS_3_15b','ON_UPDRS_3_16b','ON_UPDRS_3_17b',],\n",
    "        'rightHandTremorON': ['ON_UPDRS_3_15a','ON_UPDRS_3_16a','ON_UPDRS_3_17a',],\n",
    "        'legsON': ['ON_UPDRS_3_7a','ON_UPDRS_3_7b','ON_UPDRS_3_8a','ON_UPDRS_3_8b'],\n",
    "        'gaitON': ['ON_UPDRS_3_9','ON_UPDRS_3_10','ON_UPDRS_3_11'],\n",
    "        'postureON': ['ON_UPDRS_3_12','ON_UPDRS_3_13'],\n",
    "        'facialON': ['ON_UPDRS_3_1','ON_UPDRS_3_2',]}\n",
    "\n",
    "    for l,(off, on) in enumerate(zip(OFF_sublists.keys(),ON_sublists.keys())):\n",
    "        offList = []\n",
    "        diffList = []\n",
    "        relative_diffList = []\n",
    "        for pt in updrsScores.index:\n",
    "            offList.append(np.sum(updrsScores.loc[pt][OFF_sublists[off]]))\n",
    "            diffScore = np.sum(updrsScores.loc[pt][OFF_sublists[off]]) - np.sum(updrsScores.loc[pt][ON_sublists[on]]) # calculate difference between off and on scores\n",
    "            diffList.append(diffScore)\n",
    "            relative_diffList.append(diffScore / (len(OFF_sublists[off])*4)) # take sum-difference, normalize to list-length by dividing by potential total score\n",
    "        # create name for column\n",
    "        off_colName = off[:-3] + '_off'\n",
    "        rel_colName = off[:-3] + '_%diff'\n",
    "        colName = off[:-3] + '_diff'\n",
    "        updrsScores.insert(loc=l*2, value=diffList, column=colName)\n",
    "        updrsScores.insert(loc=l*2 +1, value=relative_diffList, column=rel_colName)\n",
    "        updrsScores.insert(loc=l*2 +2, value=offList, column=off_colName)\n",
    "    \n",
    "    # indicate which side had more arm-bradykinesia fluctuation\n",
    "    affectedSides = []\n",
    "    for pt in updrsScores.index:\n",
    "        if updrsScores.loc[pt]['leftHandBrady_diff'] > updrsScores.loc[pt]['rightHandBrady_diff']:\n",
    "            affectedSides.append('Left')\n",
    "        else:\n",
    "            affectedSides.append('Right')\n",
    "    updrsScores.insert(loc=0, value=affectedSides, column='Side')\n",
    "    # create uniform columns for bradykinesia and tremor on included side for analysis\n",
    "    for symp in ['Tremor','Brady']:\n",
    "        for var in ['_off','_diff','_%diff']:\n",
    "            updrsScores['inclSideHand%s%s' % (symp,var)] = [float(99)]*updrsScores.shape[0]\n",
    "    # fill in with values from correct sides\n",
    "    for symp in ['Tremor','Brady']:\n",
    "        for var in ['_off','_diff','_%diff']:\n",
    "            for pt in updrsScores.index:\n",
    "                if updrsScores.loc[pt]['Side'] == 'Left':\n",
    "                    updrsScores.at[pt,'inclSideHand%s%s' % (symp,var)] = updrsScores.loc[pt]['leftHand%s%s' % (symp,var)]\n",
    "                elif updrsScores.loc[pt]['Side'] == 'Right':\n",
    "                    updrsScores.at[pt,'inclSideHand%s%s' % (symp,var)] = updrsScores.loc[pt]['rightHand%s%s' % (symp,var)]\n",
    "    \n",
    "    # selecting patient with handBrady improvement on vs off, and enough data\n",
    "    for pt in updrsScores.index:\n",
    "        if updrsScores.loc[pt]['inclSideHandBrady_diff'] < 0.5:\n",
    "            updrsScores = updrsScores.drop(labels=[pt], axis=0)\n",
    "    for pt in ['022','080']: # removing 022 and 080 due to not enough data for holdout\n",
    "        updrsScores = updrsScores.drop(labels=[pt], axis=0)\n",
    "    \n",
    "    return updrsScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFeatures(minBradyDiff, updrsScores, windowLen=60):\n",
    "    '''\n",
    "    Input:\n",
    "    - minBradyDiff = minimal difference in brady-updrs-subscores to include in analysis\n",
    "    - updrsScores: dataframe with clinical scores of all patients\n",
    "    \n",
    "    Returns:\n",
    "    - accData: one dictionary with accData, each patient has a dictionary per side, \n",
    "    containing pre and post session.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # select patients to involve in analysis\n",
    "    selectedIDs = []\n",
    "    for pt in updrsScores.index:\n",
    "        if updrsScores.loc[pt]['leftHandBrady_diff'] > minBradyDiff:\n",
    "            selectedIDs.append(pt)\n",
    "        elif updrsScores.loc[pt]['rightHandBrady_diff'] > minBradyDiff:\n",
    "            selectedIDs.append(pt)\n",
    "        else:\n",
    "            continue\n",
    "    # removing 022 and 080 if included based on clinical difference, because data is not large enough for holdout\n",
    "    for pt in ['022','080']:\n",
    "        if pt in selectedIDs:\n",
    "            selectedIDs.remove(pt)\n",
    "    # dictionary for all acc data\n",
    "    features = {}\n",
    "    for pt in selectedIDs:\n",
    "        features[pt] = pd.read_csv(os.path.join(\n",
    "            path,'data','features_oct20','%s_%isec_features.csv' % (pt,windowLen)))\n",
    "    \n",
    "    return features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "updrsScores = loadUPDRSscores()\n",
    "features = loadFeatures(minBradyDiff=0.5, updrsScores=updrsScores, windowLen=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_dicts():\n",
    "    '''Creates all different outcome dictionaries'''\n",
    "    dictout = {}\n",
    "    resultsfiles = listdir(os.path.join(path,'results'))\n",
    "    for model in ['indiv','group']:\n",
    "        for cls in ['SV','RF']:\n",
    "            sel = [np.logical_and(model in name,cls in name) for name in resultsfiles]\n",
    "            mod_files = list(compress(resultsfiles, sel))\n",
    "            for fts in ['allfts','4fts']:\n",
    "                sel = [fts in name for name in mod_files]\n",
    "                sel_files = list(compress(mod_files,sel))\n",
    "                for act_filter in [True,False]:\n",
    "                    if act_filter:\n",
    "                        sel = ['ACTF' in name for name in sel_files]\n",
    "                        file = list(compress(sel_files,sel))\n",
    "                        if len(file) == 1:\n",
    "                            file = file[0]\n",
    "                            dat = pd.read_csv(os.path.join(path,'results',file), index_col=0)\n",
    "                            if model == 'indiv': # indiv models need mean,sd calculation over 41 splits\n",
    "                                temp = pd.DataFrame(index=['pred'])\n",
    "                                for col in dat.keys():\n",
    "                                    temp.at['pred',col] = np.mean(dat[col])\n",
    "                                    temp.at['pred',col+'_sd'] = np.std(dat[col])\n",
    "                                dat = temp\n",
    "                            dictout[model+'_'+cls+'_'+fts+'_actfilter'] = dat.append(pd.Series(name='p', dtype='object')) # add empty row for p\n",
    "                        else:\n",
    "                            print('No or multiple files for combination:%s, %s, %s, %s' %(model,cls,fts,act_filter)) \n",
    "                    elif act_filter == False:\n",
    "                        sel = ['ACTF' not in name for name in sel_files]\n",
    "                        file = list(compress(sel_files, sel))\n",
    "                        if len(file) == 1:\n",
    "                            file = file[0]\n",
    "                            dat = pd.read_csv(os.path.join(path,'results',file), index_col=0)\n",
    "                            if model == 'indiv': # indiv models need mean,sd calculation over 41 splits\n",
    "                                temp = pd.DataFrame(index=['pred'])\n",
    "                                for col in dat.keys():\n",
    "                                    temp.at['pred',col] = np.mean(dat[col])\n",
    "                                    temp.at['pred',col+'_sd'] = np.std(dat[col])\n",
    "                                dat = temp\n",
    "                            dictout[model+'_'+cls+'_'+fts] = dat.append(pd.Series(name='p', dtype='object')) # add empty row for p\n",
    "                        else:\n",
    "                            print('No or multiple files for combination:%s, %s, %s, %s' %(model,cls,fts,act_filter))\n",
    "    \n",
    "    ### ADD SIGNIFIANCE TESTING WHEN PERMUTATIONS ARE READY!\n",
    "    permfilelist = listdir(os.path.join(path,'results/perms')) #enter perm folder\n",
    "    for model in dictout.keys():\n",
    "        if model+'_5000perms.csv' in permfilelist: # go further for models with perm-file\n",
    "            prm = pd.read_csv(os.path.join(path,'results/perms',model+'_5000perms.csv'), index_col=0)\n",
    "            for col in dictout[model].keys():\n",
    "                if col[-2:] != 'sd': # exclude sd columns\n",
    "                    v = dictout[model].loc['pred'][col] # determine value of pt+metric\n",
    "                    p = sum(prm[col]>v)/len(prm[col]) # calculate part of perms higher\n",
    "                    dictout[model].at['p',col] = p # add p value to outcome dataframe\n",
    "    \n",
    "    return dictout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indiv_SV_allfts_actfilter (2, 240)\n",
      "indiv_SV_allfts (2, 240)\n",
      "indiv_SV_4fts_actfilter (2, 240)\n",
      "indiv_SV_4fts (2, 240)\n",
      "indiv_RF_allfts_actfilter (2, 240)\n",
      "indiv_RF_allfts (2, 240)\n",
      "indiv_RF_4fts_actfilter (2, 240)\n",
      "indiv_RF_4fts (2, 240)\n",
      "group_SV_allfts_actfilter (2, 120)\n",
      "group_SV_allfts (2, 120)\n",
      "group_SV_4fts_actfilter (2, 120)\n",
      "group_SV_4fts (2, 120)\n",
      "group_RF_allfts_actfilter (2, 120)\n",
      "group_RF_allfts (2, 120)\n",
      "group_RF_4fts_actfilter (2, 120)\n",
      "group_RF_4fts (2, 120)\n"
     ]
    }
   ],
   "source": [
    "dictout = create_result_dicts()\n",
    "# to check dict out shapes\n",
    "keys=list(dictout.keys())\n",
    "for key in keys:\n",
    "    print(key,dictout[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Descriptives of patient population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of included patients: 20\n",
      "\n",
      "totalUPDRS3_On\n",
      "Mean: 27.10 (sd: 9.60)\n",
      "Min: 11.00, max: 42.00\n",
      "\n",
      "totalUPDRS3_Off\n",
      "Mean: 43.75 (sd: 11.63)\n",
      "Min: 29.00, max: 67.00\n",
      "\n",
      "totalUPDRS3_Diff\n",
      "Mean: 16.65 (sd: 8.57)\n",
      "Min: -4.00, max: 38.00\n",
      "\n",
      "inclSideHandBrady_off\n",
      "Mean: 8.85 (sd: 2.26)\n",
      "Min: 6.00, max: 13.00\n",
      "\n",
      "inclSideHandTremor_off\n",
      "Mean: 3.85 (sd: 2.67)\n",
      "Min: 0.00, max: 9.00\n",
      "\n",
      "inclSideHandBrady_diff\n",
      "Mean: 3.90 (sd: 1.95)\n",
      "Min: 1.00, max: 7.00\n",
      "\n",
      "inclSideHandTremor_diff\n",
      "Mean: 2.10 (sd: 2.32)\n",
      "Min: 0.00, max: 9.00\n",
      "\n",
      "bradyBody_diff\n",
      "Mean: 0.85 (sd: 0.57)\n",
      "Min: 0.00, max: 2.00\n",
      "\n",
      "legs_diff\n",
      "Mean: 0.85 (sd: 3.09)\n",
      "Min: -6.00, max: 6.00\n",
      "\n",
      "gait_diff\n",
      "Mean: 0.95 (sd: 0.97)\n",
      "Min: 0.00, max: 3.00\n",
      "\n",
      "posture_diff\n",
      "Mean: 0.45 (sd: 1.12)\n",
      "Min: -1.00, max: 3.00\n",
      "\n",
      "facial_diff\n",
      "Mean: 1.15 (sd: 0.91)\n",
      "Min: -1.00, max: 3.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clin_vars = ['totalUPDRS3_On', 'totalUPDRS3_Off', 'totalUPDRS3_Diff', \n",
    "             'inclSideHandBrady_off',  'inclSideHandTremor_off',\n",
    "             'inclSideHandBrady_diff',  'inclSideHandTremor_diff',\n",
    "       'bradyBody_diff','legs_diff', 'gait_diff', 'posture_diff', 'facial_diff',] \n",
    "with open('results/updrs_descriptives_n%i.txt' % updrsScores.shape[0], 'w') as f:\n",
    "            print('UPDRS Descriptives\\n\\n', file=f)\n",
    "print('Number of included patients: %i' % updrsScores.shape[0])\n",
    "print()\n",
    "for var in clin_vars:\n",
    "    print(var)\n",
    "    print('Mean: %.2f (sd: %.2f)' % (np.mean(updrsScores[var]),np.std(updrsScores[var])))\n",
    "    print('Min: %.2f, max: %.2f' % (np.min(updrsScores[var]),np.max(updrsScores[var])))\n",
    "    print()\n",
    "    with open('results/updrs_descriptives_n%i.txt' % updrsScores.shape[0], 'a') as f:\n",
    "        print('%s:\\nMean: %.2f (sd: %.2f)\\n' % \n",
    "              (var,np.mean(updrsScores[var]),np.std(updrsScores[var])), file=f)    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Differences in 4 candidate movement features between pre- and post-med states\n",
    "\n",
    "Analyze variance in features between pre and post-medication features.\n",
    "\n",
    "Standardised features will be used, just as in predictive analysis. Features are standardised individually, only pre-medication features are used as reference for the standardisation function.\n",
    "\n",
    "4 Main features pragmatically chosen based on importance in literature. Variance analysis will be conducted with multi-variate Analysis Of Variance (MANOVA), and 4 seperate repeated measures ANOVA as post-hoc test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation, normalisation of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zScoreFeatures(features, scaling):\n",
    "    \n",
    "    '''\n",
    "    Features is dict with feature dataframe for every patient separate. Inlcudes all on and off features per minute.\n",
    "    '''\n",
    "    ## Analyze z-scored features, on vs off\n",
    "    zFeats = {}\n",
    "    firstPt = list(features.keys())[0]\n",
    "    allFts = [f for f in features[firstPt].keys().tolist() if f != 'medState']\n",
    "    ## Empirical choise of 3 main features:\n",
    "    mainFts = ['SVM_maxAcc','SVM_coefVar','SVM_RMS','SVM_specPow_totalu4Hz']\n",
    "\n",
    "    z_total = pd.DataFrame(columns = allFts)\n",
    "    z_pre = pd.DataFrame(columns = allFts)\n",
    "    z_post = pd.DataFrame(columns = allFts)\n",
    "    group_ft = pd.DataFrame(columns = allFts)\n",
    "    \n",
    "    list_pt = []\n",
    "    \n",
    "\n",
    "    for pt in list(features.keys()):\n",
    "\n",
    "        # minSize is shortest length of samples(rows) per pt-side of dataframe, on or off samples\n",
    "        minSize = min(sum(features[pt]['medState']==0),sum(features[pt]['medState']==1))\n",
    "        # create predData per pt, per side, with balanced rows pre and post med (minSize)\n",
    "        predData = pd.concat([features[pt][features[pt]['medState']==0][:minSize],features[pt][features[pt]['medState']==1][:minSize]],axis=0,sort=False).reset_index(drop=True)\n",
    "        # add un-standarized features to group_z, standarization follows later on full group\n",
    "        group_ft = pd.concat([group_ft,predData],axis=0,sort=False).reset_index(drop=True)\n",
    "        # collect pt-numbers\n",
    "        list_pt.extend([pt]*minSize*2)\n",
    "\n",
    "        # standarize data or normalize data\n",
    "        if scaling == 'Stand':\n",
    "            scaler = StandardScaler()\n",
    "        elif scaling == 'Norm':\n",
    "            scaler = MinMaxScaler()\n",
    "            \n",
    "        if scaling != 'None':\n",
    "            scaler.fit(predData[predData['medState']==0][allFts]) # standardized only on pre-medication data\n",
    "    #         scaler.fit(predData[allFts]) # use pre and post data for standarization (total mean=0, sd=1)\n",
    "\n",
    "            # create x and y dataset for this patient\n",
    "            x = pd.DataFrame(data = scaler.transform(predData[allFts]), columns = allFts)\n",
    "            y = predData['medState']\n",
    "            # adding x and y again to one df\n",
    "            x['medState'] = y\n",
    "            zFeats[pt] = x\n",
    "            z_total = pd.concat([z_total,x],axis=0,sort=False).reset_index(drop=True)\n",
    "            z_pre = pd.concat([z_pre,x[x['medState']==0]],axis=0,sort=False).reset_index(drop=True)\n",
    "            z_post = pd.concat([z_post,x[x['medState']==1]],axis=0,sort=False).reset_index(drop=True)\n",
    "        \n",
    "        elif scaling == 'None':\n",
    "            z_total = pd.concat([z_total,predData],axis=0,sort=False).reset_index(drop=True)\n",
    "    \n",
    "    z_total['pt'] = list_pt\n",
    "    print(z_total.shape, z_pre.shape, z_post.shape)\n",
    "\n",
    "    return z_total, z_pre, z_post, zFeats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2380, 105) (1190, 104) (1190, 104)\n",
      "(2380, 105) (1190, 104) (1190, 104)\n"
     ]
    }
   ],
   "source": [
    "mainFts = ['SVM_maxAcc','SVM_coefVar','SVM_RMS','SVM_specPow_totalu4Hz']\n",
    "z_total, z_pre, z_post, zFeatsPt = zScoreFeatures(features, 'Stand')\n",
    "n_total, n_pre, n_post, nFeatsPt = zScoreFeatures(features, 'Norm')\n",
    "# raw_total,_,_,_ = zScoreFeatures(features, 'None')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MANOVA - Multifactorial Analysis of Variance\n",
    "To test if the 20 patients differ in pre-medication and post-medication state based on 4 main features which are averaged per patient, per medication state.\n",
    "Features are standardised individually. Only pre-medication data is used to fit standardisation formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manova(z_or_n, save):\n",
    "    '''\n",
    "    # Literature on MANOVA:\n",
    "    # https://www.marsja.se/python-manova-made-easy-using-statsmodels/\n",
    "    # https://www.real-statistics.com/multivariate-statistics/multivariate-analysis-of-variance-manova/two-way-manova/\n",
    "    # https://github.com/statsmodels/statsmodels/issues/6464\n",
    "    # https://statistics.laerd.com/spss-tutorials/two-way-manova-using-spss-statistics.php\n",
    "\n",
    "    For unbalanced groups\" `typ=3`. Type 3 sums of squares (SS) is \n",
    "    recommended for an unbalanced design for multifactorial ANOVA.\n",
    "    ols = Ordinary Least Squares (OLS) model\n",
    "    error: https://stackoverflow.com/questions/53489106/statsmodels-ols-inf-or-nan-error-when-there-is-none-in-dataset'''\n",
    "### Create (M)ANOVA table in long data form with mean values per patient\n",
    "    if z_or_n == 'std':\n",
    "        z_or_n = z_total # define to use stand. or norm. data\n",
    "    elif z_or_n == 'norm':\n",
    "        z_or_n = n_total # define to use stand. or norm. data\n",
    "    anova_data = pd.DataFrame(columns=['pt','medState']+mainFts)\n",
    "    dat={}\n",
    "    for ft in mainFts:\n",
    "        dat['pt']=[]\n",
    "        dat['medState']=[]\n",
    "        dat[ft]=[]\n",
    "        for p,pt in enumerate(features.keys()):\n",
    "            for med in [0,1]:\n",
    "                dat['pt'].append(p)\n",
    "                dat['medState'].append(med)\n",
    "                m = np.mean(\n",
    "                    z_or_n[np.logical_and(\n",
    "                        z_or_n['pt']==pt,z_or_n['medState']==med)]\n",
    "                    [ft])\n",
    "                dat[ft].append(m)\n",
    "    for col in anova_data.keys():\n",
    "        anova_data[col] = dat[col]\n",
    "    \n",
    "# anova_data.to_csv(os.path.join(path,'manova_data.csv'))\n",
    "    maov = MANOVA(endog= anova_data[mainFts], exog=anova_data['medState']) # \n",
    "    print(maov.mv_test())\n",
    "    if save:\n",
    "        with open('results/manova_table.txt', 'w') as f:\n",
    "            print(maov.mv_test(), file=f)\n",
    "    return anova_data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Multivariate linear model\n",
      "============================================================\n",
      "                                                            \n",
      "------------------------------------------------------------\n",
      "           x0           Value  Num DF  Den DF F Value Pr > F\n",
      "------------------------------------------------------------\n",
      "          Wilks' lambda 0.3878 4.0000 36.0000 14.2080 0.0000\n",
      "         Pillai's trace 0.6122 4.0000 36.0000 14.2080 0.0000\n",
      " Hotelling-Lawley trace 1.5787 4.0000 36.0000 14.2080 0.0000\n",
      "    Roy's greatest root 1.5787 4.0000 36.0000 14.2080 0.0000\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anova_data = manova('std',False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Hoc Analysis\n",
    "1: Repeated Measures ANOVA to find individual p-values of 4 features  leading to signicicant difference in MANOVA.\n",
    "\n",
    "2: Correct p-value for multiple comparison with False Detection Rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posthoc(anova_data, save):\n",
    "    '''\n",
    "    Analyse single features with repeated measures ANOVA (equal to t-test) \n",
    "    to find which features causes signifcant difference found in MANOVA.\n",
    "    ''' \n",
    "    if save:\n",
    "    # to write text result in to a text-file\n",
    "        with open('results/posthoc_rm_anova.txt', 'w') as f:\n",
    "            print('Post-Hoc analysis after MANOVA, with repeated measures ANOVA (4 features)\\n', file=f)\n",
    "\n",
    "    for ft in mainFts:\n",
    "        rm1way = AnovaRM(anova_data, ft, 'pt',within=['medState']) \n",
    "        # AnovaRM: first data, then independet var, subject ident, within=independet var\n",
    "        res = rm1way.fit()\n",
    "        if save:\n",
    "            with open('results/posthoc_rm_anova.txt', 'a') as f:\n",
    "                print(ft,':', file=f)\n",
    "                print(res, file=f)\n",
    "        print(ft,':')\n",
    "        print(res)\n",
    "\n",
    "    ## FDR corrected significancies\n",
    "    p_fdr,_,_,_ = multipletests([0.2501,0.0042,0.8538,0.3231],\n",
    "                                    alpha=0.05, method='fdr_bh')\n",
    "    sign_main_fts = list(compress(mainFts,p_fdr))\n",
    "    print()\n",
    "    print('Feature(s) with signficant difference:',sign_main_fts) \n",
    "    if save:\n",
    "        with open('results/posthoc_rm_anova.txt', 'a') as f:\n",
    "            print('\\nFeature(s) with signficant difference:',sign_main_fts, file=f)    \n",
    "\n",
    "    return sign_main_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_maxAcc :\n",
      "                Anova\n",
      "======================================\n",
      "         F Value Num DF  Den DF Pr > F\n",
      "--------------------------------------\n",
      "medState  1.4074 1.0000 19.0000 0.2501\n",
      "======================================\n",
      "\n",
      "SVM_coefVar :\n",
      "                Anova\n",
      "======================================\n",
      "         F Value Num DF  Den DF Pr > F\n",
      "--------------------------------------\n",
      "medState 10.5744 1.0000 19.0000 0.0042\n",
      "======================================\n",
      "\n",
      "SVM_RMS :\n",
      "                Anova\n",
      "======================================\n",
      "         F Value Num DF  Den DF Pr > F\n",
      "--------------------------------------\n",
      "medState  0.0349 1.0000 19.0000 0.8538\n",
      "======================================\n",
      "\n",
      "SVM_specPow_totalu4Hz :\n",
      "                Anova\n",
      "======================================\n",
      "         F Value Num DF  Den DF Pr > F\n",
      "--------------------------------------\n",
      "medState  1.0293 1.0000 19.0000 0.3231\n",
      "======================================\n",
      "\n",
      "\n",
      "Feature(s) with signficant difference: ['SVM_coefVar']\n"
     ]
    }
   ],
   "source": [
    "sign_feats = posthoc(anova_data, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of 4 candidate features with violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotViolins(zmethod, sign_feats, save):\n",
    "    feats = ['SVM_maxAcc','SVM_coefVar','SVM_RMS','SVM_specPow_totalu4Hz']\n",
    "    ls = 20 # labelsize\n",
    "    ts = 24 # titlesize\n",
    "    # colors to use for violinplot\n",
    "    col1,col2 = list(sns.color_palette(\"Set2\"))[1],list(sns.color_palette(\"Paired\"))[2]\n",
    "    if zmethod == 'std':\n",
    "        z_or_n = z_total # define to use stand. or norm. data\n",
    "        y_label='Patient mean of \\nstandarized feature'\n",
    "    elif zmethod == 'nrm':\n",
    "        z_or_n = n_total\n",
    "        y_label='Patient mean of \\nnormalized feature'\n",
    "#     elif zmethod == 'None':\n",
    "#         z_or_n = raw_total\n",
    "#         y_label='Patient mean of feature' \n",
    "    anova_data = pd.DataFrame(columns=['pt','medState']+mainFts)\n",
    "    dat={}\n",
    "    for ft in mainFts:\n",
    "        dat['pt']=[]\n",
    "        dat['medState']=[]\n",
    "        dat[ft]=[]\n",
    "        for p,pt in enumerate(features.keys()):\n",
    "            for med in [0,1]:\n",
    "                dat['pt'].append(p)\n",
    "                dat['medState'].append(med)\n",
    "                m = np.mean(\n",
    "                    z_or_n[np.logical_and(\n",
    "                        z_or_n['pt']==pt,z_or_n['medState']==med)]\n",
    "                    [ft])\n",
    "                dat[ft].append(m)\n",
    "    for col in anova_data.keys():\n",
    "        anova_data[col] = dat[col]\n",
    "    \n",
    "    violin_data = pd.melt(anova_data, id_vars=['medState'], \n",
    "            value_vars=mainFts)\n",
    "    violin_data.loc[violin_data['medState']==0,'medState'] = 'Pre-med (OFF)'\n",
    "    violin_data.loc[violin_data['medState']==1,'medState'] = 'Post-med (ON)'\n",
    "    violin_data = violin_data.rename(columns={'variable':'Features',\n",
    "        'medState':'Medication Status','value':y_label})\n",
    "\n",
    "    # plot violin\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    a = sns.violinplot(ax=ax, x='Features',y=y_label,\n",
    "            hue='Medication Status',\n",
    "        data=violin_data, palette=[col1,col2], split=True,scale='count',\n",
    "                        inner='stick', figsize=(24,8))\n",
    "    # Add significancy stars\n",
    "    for n,ft in enumerate(mainFts):\n",
    "        if ft  in sign_feats:\n",
    "            if zmethod=='std':\n",
    "                ax.annotate('*', xy= (n, 2.1), fontsize=34, color='red')\n",
    "            elif zmethod=='nrm':\n",
    "                ax.annotate('*', xy= (n, .9), fontsize=34, color='red')\n",
    "#     ax.plot([],[],'',c='white',label='* = Significancy (alpha = 0.05')\n",
    "   \n",
    "    ax.set_title('Main Features during Pre- vs Post-medication States', size=ts)\n",
    "    if zmethod=='std':\n",
    "        ax.set_ylim(-2,2.5)\n",
    "        ax.set_yticks(np.arange(-2,2.5,1))\n",
    "        ax.set_yticklabels(np.arange(-2,2.5,1),size=ls)\n",
    "        (xmin,xmax) = ax.get_xlim()\n",
    "        ax.hlines(np.linspace(-2,2,5), xmin= xmin, xmax= xmax, color='gray', alpha=0.5)\n",
    "    elif zmethod=='nrm':\n",
    "        ax.set_ylim(0,1.1)\n",
    "        ax.set_yticks(np.linspace(0,1,5))\n",
    "        ax.set_yticklabels(np.linspace(0,1,5),size=ls)\n",
    "        (xmin,xmax) = ax.get_xlim()\n",
    "        ax.hlines(np.linspace(0,1,5), xmin= xmin, xmax= xmax, color='gray', alpha=0.5)\n",
    "    ax.set_xticklabels(['Maximum\\nAcceleration','Coefficient\\nof Variance',\n",
    "                        'Root Mean\\nSquare','Spectral Power\\nbelow 4 Hz'], size=ls)\n",
    "    ax.set_xlabel('Features', size=ls)\n",
    "    ax.set_ylabel(y_label, size=ls)\n",
    "    ax.legend(fontsize=ls, )\n",
    "    fig = ax.get_figure()\n",
    "    if save:\n",
    "        fig.savefig(os.path.join(path,'figures/%s_violin_4fts_sig.png' %zmethod), dpi=300)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotViolins('std', sign_feats , True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotViolins('nrm', sign_feats, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification of Pre- and Post-med states \n",
    "\n",
    "Results and figures are saved to repective folders in main path. Each can be created for every model (SV vs RF, group vs individual), and data selection approach (4 vs all features, with vs without activity filtering).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a: Barplots to visualize classification accuracy and auroc for two selected models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionBars(two_models, model_labels, fig_title, save, save_filename):\n",
    "    \n",
    "    '''Always shows Accuracy and AUROC, number of lists to compare decides number of figures.\n",
    "    Lists to compare has to be list of lists of two groups.[[A,B], [C,D], [A,C]]\n",
    "    Colors to visualize.\n",
    "    '''\n",
    "    pts = np.unique([col[:3] for col in dictout[two_models[0]].keys()])    \n",
    "    # settings\n",
    "    ls= 20 # standard labelsize\n",
    "    ts= 24 # standard titlesize \n",
    "    fig,axes = plt.subplots(2,1, figsize=(20,12))\n",
    "    colors = ['green','salmon'] # colors in respective order\n",
    "    widths = [-0.3,0.3] # position on x-axis for bars\n",
    "    annpos = [-0.2,0.1] # corrections to plosition the annotation stars correctly\n",
    "    for fig_row, metric in enumerate(['Accuracy','AUROC']):\n",
    "        # show individual means with significancy (n=20) per outcome-metric\n",
    "        for d,dct in enumerate(two_models):\n",
    "            heights = []\n",
    "            sds = []\n",
    "            for key in dictout[dct].keys():\n",
    "                if np.logical_and(metric in key,len(key) == len(metric)+4): # filters out XXX_METRIC keys\n",
    "                    heights.append(dictout[dct].loc['pred'][key])\n",
    "                if np.logical_and(metric in key, 'sd' in key): # filters out all '_sd' keys\n",
    "                    sds.append(dictout[dct].loc['pred'][key])\n",
    "            if 'group' in dct:\n",
    "                sds = [0]*len(pts)\n",
    "#             print('Analysis: %s (n=%i), mean %s = %.3f, sd = %.2f' % \n",
    "#                   (dct,len(heights),metric,np.mean(heights),np.std(heights)))\n",
    "            heights = [np.mean(heights)]+heights\n",
    "            list_sd = [np.std(heights)]+sds\n",
    "            axes[fig_row].bar(x=np.arange(21), height=heights, yerr=list_sd,\n",
    "                    width=widths[d], align='edge', color=colors[d], label= model_labels[d] )\n",
    "\n",
    "#                 # ADD LATER: significancy level with star annotation, and FDR correction!\n",
    "#                 for x_pos,pt in enumerate(table.index):\n",
    "#                     if table.loc[pt][methods[method]+metric+'_sign'] == 1:\n",
    "#                         star_heigth = heights[x_pos+1] + list_errs[x_pos+1]/2 + 0.1\n",
    "#                         axes[fig_row].annotate('*', xy=(x_pos+1 +annpos[m], star_heigth), fontsize=20, color=colors[m])\n",
    "            # legend item for sign-asterixes\n",
    "#             axes[fig_row].plot([],[],'',c='white',label='* = Significancy, p = 0.05')\n",
    "\n",
    "        # figure design/layout\n",
    "        axes[fig_row].tick_params(labelsize=ls)\n",
    "        x_labels = ['Mean']\n",
    "        x_labels.extend(pts)\n",
    "        axes[fig_row].set_xticklabels(x_labels)\n",
    "        axes[fig_row].set_xticks(np.arange(len(x_labels)))\n",
    "        axes[fig_row].set_title(metric, fontsize=ts)\n",
    "        axes[fig_row].axhline(y=0.5, ls='--', c='k', lw=1.5, label='Chance-level')\n",
    "        for yline in [0.2,0.4,0.6,0.8]:\n",
    "            axes[fig_row].axhline(y=yline, ls='-', c='gray', lw=0.5, )\n",
    "        for yline in [0.1,0.3,0.7,0.9]:\n",
    "            axes[fig_row].axhline(y=yline, ls='--', c='gray', lw=0.3, )\n",
    "        axes[fig_row].axhline(y=1, ls='-', c='k', lw=0.5, )\n",
    "        axes[fig_row].set_ylim(0, 1.1)\n",
    "        axes[fig_row].set_yticks(np.arange(0,1.1,0.2))\n",
    "        axes[fig_row].legend(fontsize=ls, loc='upper right', ncol=4)\n",
    "    plt.suptitle(fig_title, fontsize=ts+6, y=.98)\n",
    "    plt.tight_layout(h_pad=1, pad=2)\n",
    "\n",
    "\n",
    "    if save == True:\n",
    "        plt.savefig(os.path.join(path,'figures',save_filename), dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of groups to pick from for comparison:\n",
      "\n",
      "indiv_SV_allfts_actfilter\n",
      "indiv_SV_allfts\n",
      "indiv_SV_4fts_actfilter\n",
      "indiv_SV_4fts\n",
      "indiv_RF_allfts_actfilter\n",
      "indiv_RF_allfts\n",
      "indiv_RF_4fts_actfilter\n",
      "indiv_RF_4fts\n",
      "group_SV_allfts_actfilter\n",
      "group_SV_allfts\n",
      "group_SV_4fts_actfilter\n",
      "group_SV_4fts\n",
      "group_RF_allfts_actfilter\n",
      "group_RF_allfts\n",
      "group_RF_4fts_actfilter\n",
      "group_RF_4fts\n"
     ]
    }
   ],
   "source": [
    "print('List of groups to pick from for comparison:\\n')\n",
    "for key in list(dictout.keys()):\n",
    "    print('%s' % key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictionBars(['group_SV_4fts_actfilter','indiv_SV_allfts_actfilter'],\n",
    "#                         ['4 feature model (SV group, filtered)',\n",
    "#                          '103 feature model (SV individual, filtered)'], \n",
    "#                'Models based on 4 vs 103 features', \n",
    "#                True, 'bars_4_vs_103fts_(best)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## significance to add\n",
    "# predictionBars(['indiv_SV_allfts_actfilter','group_SV_allfts_actfilter'], \n",
    "#                ['Individual','Group'], \n",
    "#                'Individual vs Group Model (both SV and activity filtered)', \n",
    "#                False, 'bars_GroupVsIndiv_(SV_actfilter)')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PtId</th>\n",
       "      <th>002</th>\n",
       "      <th>012</th>\n",
       "      <th>013</th>\n",
       "      <th>014</th>\n",
       "      <th>015</th>\n",
       "      <th>017</th>\n",
       "      <th>018</th>\n",
       "      <th>023</th>\n",
       "      <th>024</th>\n",
       "      <th>038</th>\n",
       "      <th>039</th>\n",
       "      <th>043</th>\n",
       "      <th>047</th>\n",
       "      <th>051</th>\n",
       "      <th>054</th>\n",
       "      <th>058</th>\n",
       "      <th>063</th>\n",
       "      <th>065</th>\n",
       "      <th>079</th>\n",
       "      <th>090</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inclSideHandBrady_diff</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inclSideHandTremor_diff</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PtId                     002  012  013  014  015  017  018  023  024  038  \\\n",
       "inclSideHandBrady_diff   4.0  2.0  6.0  2.0  5.0  4.0  1.0  2.0  4.0  7.0   \n",
       "inclSideHandTremor_diff  2.0  6.0  9.0  1.0  1.0  0.0  1.0  3.0  4.0  3.0   \n",
       "\n",
       "PtId                     039  043  047  051  054  058  063  065  079  090  \n",
       "inclSideHandBrady_diff   6.0  4.0  2.0  7.0  6.0  5.0  4.0  1.0  1.0  5.0  \n",
       "inclSideHandTremor_diff  0.0  0.0  2.0  0.0  1.0  0.0  2.0  0.0  2.0  5.0  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updrsScores[['inclSideHandBrady_diff','inclSideHandTremor_diff']].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b: Equality-plots to compare classification results between two approaches per participant (e.g. individual vs group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equality_plots(models,mod_labels,blackwhite,fig_title,save,save_filename):\n",
    "    '''\n",
    "    models = list of two models from dictout.\n",
    "    mod_labels= list of the figure labels corresponding to the two models.\n",
    "    blackwhite = Boolean\n",
    "    fig_title = string for title in fig.\n",
    "    save=Boolean, save_filename = string to store figure-file.\n",
    "    \n",
    "    P-value correction (and choice of type) for multiple comparison is done within script.\n",
    "    \n",
    "    Makes two ewuality plots, AUROC (l) and Accuracy (r), \n",
    "    with indications of significances.\n",
    "    First model in list will be X-AXIS, second will be Y-AXIS.'''\n",
    "    \n",
    "    metrics = ['AUROC','Accuracy']\n",
    "    p_tresh = 0.05\n",
    "    cols = ['%s_%s'%(mod,metr) for mod in ['1','2'] for metr in metrics]\n",
    "    cols = cols+ [col+'_sign' for col in cols]+['AUROC_sign_comb','Accuracy_sign_comb']\n",
    "    eq_dat = pd.DataFrame(index=updrsScores.index, columns=cols)\n",
    "    \n",
    "    for n,mod in enumerate(models): # create eq_dat\n",
    "        for met in metrics:\n",
    "            for pt in eq_dat.index:\n",
    "                eq_dat.at[pt,'%i_%s' % (n+1,met) ] = dictout[mod].loc['pred']['%s_%s' % (pt,met)]\n",
    "# #                 # signifiance without correction:\n",
    "#                 eq_dat.at[pt,'%i_%s_sign' % (n+1,met) ] = dictout[mod].loc['p']['%s_%s' % (pt,met)] < p_tresh\n",
    "#             # significance with multicomparison p-correction\n",
    "            ps = [dictout[mod].loc['p']['%s_%s' % (pt,met)] for pt in eq_dat.index]\n",
    "            ps_fdr,_,_,_ = multipletests(ps,alpha=p_tresh, method='fdr_bh')\n",
    "            eq_dat['%i_%s_sign' % (n+1,met)] = ps_fdr.astype(int)\n",
    "    for pt in eq_dat.index:\n",
    "        for met in metrics: # combined sign: 1= only 1, 2=only 2, 3=both not, 4 BOTH SIGN\n",
    "            if np.logical_and(eq_dat.loc[pt]['1_%s_sign' % met] == 1,eq_dat.loc[pt]['2_%s_sign' % met] == 0):\n",
    "                eq_dat.at[pt,'%s_sign_comb' % met] = 1\n",
    "            elif np.logical_and(eq_dat.loc[pt]['1_%s_sign' % met] == 0,eq_dat.loc[pt]['2_%s_sign' % met] == 1):\n",
    "                eq_dat.at[pt,'%s_sign_comb' % met] = 2        \n",
    "            elif np.logical_and(eq_dat.loc[pt]['1_%s_sign' % met] == 0,eq_dat.loc[pt]['2_%s_sign' % met] == 0):\n",
    "                eq_dat.at[pt,'%s_sign_comb' % met] = 3     \n",
    "            elif np.logical_and(eq_dat.loc[pt]['1_%s_sign' % met] == 1,eq_dat.loc[pt]['2_%s_sign' % met] == 1):\n",
    "                eq_dat.at[pt,'%s_sign_comb' % met] = 4\n",
    "            else:\n",
    "                print('why')\n",
    "\n",
    "    fig, axes = plt.subplots(1,len(metrics),figsize=(26,12))\n",
    "    dotSize = 250\n",
    "    fs=30\n",
    "    ts=36\n",
    "    for n,metric in enumerate(metrics):\n",
    "        x_ax = '1_%s' % metric\n",
    "        y_ax = '2_%s' % metric\n",
    "        if blackwhite:\n",
    "            # use triangle for ind-sig, round for ind-non-sig\n",
    "            # use filled for group-sig, non-filled for group-non-sig\n",
    "            scatter = axes[n].scatter(eq_dat[eq_dat['%s_sign_comb' % met]==4][x_ax],eq_dat[eq_dat['%s_sign_comb' % met]==4][y_ax], \n",
    "                                      s=dotSize, lw=2, c='k',marker='^',  label='Both significant') #edgecolors='k', facecolors='none',\n",
    "            scatter = axes[n].scatter(eq_dat[eq_dat['%s_sign_comb' % met]==1][x_ax],eq_dat[eq_dat['%s_sign_comb' % met]==1][y_ax], \n",
    "                                      s=dotSize, lw=2,marker='^', label='Only %s significant' % mod_labels[0],edgecolors='k', facecolors='none',)\n",
    "            scatter = axes[n].scatter(eq_dat[eq_dat['%s_sign_comb' % met]==2][x_ax],eq_dat[eq_dat['%s_sign_comb' % met]==2][y_ax], s=dotSize, lw=2,c='k',\n",
    "                                      marker='o',  label= 'Only %s significant' % mod_labels[1],   ) #edgecolors='k', facecolors='none',\n",
    "            scatter = axes[n].scatter(eq_dat[eq_dat['%s_sign_comb' % met]==3][x_ax],eq_dat[eq_dat['%s_sign_comb' % met]==3][y_ax], s=dotSize, lw=2,\n",
    "                                      marker='o', label='None significant',edgecolors='k', facecolors='none',)\n",
    "        else:\n",
    "            # use triangle for ind-sig, round for ind-non-sig\n",
    "            # use filled for group-sig, non-filled for group-non-sig\n",
    "            scatter = axes[n].scatter(eq_dat[eq_dat['%s_sign_comb' % met]==4][x_ax],eq_dat[eq_dat['%s_sign_comb' % met]==4][y_ax],\n",
    "                                      s=dotSize, lw=2, color='green',marker='o',  label='Both significant') \n",
    "            scatter = axes[n].scatter(eq_dat[eq_dat['%s_sign_comb' % met]==1][x_ax],eq_dat[eq_dat['%s_sign_comb' % met]==1][y_ax], \n",
    "                                      s=dotSize, lw=2,color='darkblue',marker='o', label='Only %s \\nsignificant' % mod_labels[0],)\n",
    "            scatter = axes[n].scatter(eq_dat[eq_dat['%s_sign_comb' % met]==2][x_ax],eq_dat[eq_dat['%s_sign_comb' % met]==2][y_ax], \n",
    "                                      s=dotSize, lw=2,color='goldenrod',marker='o',  label='Only %s \\nsignificant' % mod_labels[1],   ),\n",
    "            scatter = axes[n].scatter(eq_dat[eq_dat['%s_sign_comb' % met]==3][x_ax],eq_dat[eq_dat['%s_sign_comb' % met]==3][y_ax], \n",
    "                                      s=dotSize, lw=2,edgecolors='k',facecolors='lightgray',marker='o', label='None significant',)\n",
    "\n",
    "        # plot equality line\n",
    "        xStart, xEnd, yStart, yEnd = 0.2, 1.0, 0.2, 1.0\n",
    "        axes[n].axis([xStart, xEnd, yStart, yEnd])\n",
    "        axes[n].plot(np.linspace(xStart,xEnd,10),np.linspace(yStart,yEnd,10), c='k', \n",
    "                         ls='dotted',lw=5, label='Equality of models',alpha=0.7)\n",
    "        # details for main figure\n",
    "        axes[n].hlines([0.4,0.6,0.8], xmin=0.2, xmax=1, color='gray', alpha=0.5)\n",
    "        axes[n].vlines([0.4,0.6,0.8], ymin=0.2, ymax=1, color='gray', alpha=0.5)\n",
    "        axes[n].set_xlabel('%s score' % mod_labels[0], size=fs)\n",
    "        axes[n].set_ylabel('%s score' % mod_labels[1], size=fs)\n",
    "        axes[n].set_title('%s' % (metric), size=ts)\n",
    "#         axes[n].legend(loc='lower left',fontsize=24, )\n",
    "        axes[n].tick_params(labelsize=fs,direction='out', length=6, width=2, colors='k',\n",
    "               grid_color='r', grid_alpha=0.5)\n",
    "    plt.legend(loc='upper left',fontsize=24, bbox_to_anchor=(1.05, 1),)\n",
    "    plt.suptitle(fig_title, fontsize=ts+6, y=.98)\n",
    "    plt.tight_layout(h_pad=1, pad=2)\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(path,'figures',save_filename), dpi=150)\n",
    "    plt.show()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best models based on 4 vs 103 features\n",
    "# equality_plots(['group_SV_4fts_actfilter','indiv_SV_allfts_actfilter'],\n",
    "#                         ['4 feature model \\n(SV group, filtered)',\n",
    "#                          '103 feature model \\n(SV individual, filtered)'],\n",
    "#                         False, 'Models with 4 vs 103 features (both group SV, activity filtered)',\n",
    "#                         True,'EQplot_4_vs_103fts_(best)(fdr)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best individual vs best group model\n",
    "# equality_plots(['indiv_SV_allfts_actfilter','group_SV_allfts_actfilter'],\n",
    "#                         ['Individual model','Group model'],\n",
    "#                         False, 'Individual vs Group models (both SV, activity filtered)',\n",
    "#                         True,'EQplot_Indiv_vs_Group_SV_actfilter(fdr)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model without vs with filtering\n",
    "# equality_plots(['indiv_SV_allfts','indiv_SV_allfts_actfilter'],\n",
    "#                         ['Not filtered\\n(individual SV)','Activity filtered\\n(individual SV)'],\n",
    "#                         False, 'Best model without vs best model with activity filtering',\n",
    "#                         True,'EQplot_W_vs_WO_actfilter_SV_indiv(fdr)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Correlating predictive outcomes with clinical scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlations updrs sub-scores with outcome, new datasplitting analyses\n",
    "\n",
    "def plot_clin_corr(models,mod_labels,save,save_filename):\n",
    "    '''\n",
    "    models: defines one or two models which are compared with subscores\n",
    "    '''\n",
    "    subscores = ['inclSideHandBrady_%diff','inclSideHandTremor_%diff',\n",
    "                     'bradyBody_%diff','legs_%diff','gait_%diff',\n",
    "                     'posture_%diff','facial_%diff' ]\n",
    "    subscorelabels = ['Hand brady','Hand tremor','Body brady','Legs','Gait',\n",
    "                     'Posture','Face' ]\n",
    "    metrics = ['AUROC', 'Accuracy']\n",
    "    corr_dat = pd.DataFrame(index=updrsScores.index) # make df for this plot\n",
    "    for sub in subscores:\n",
    "        corr_dat[sub] = updrsScores[sub] # import subscores per pt\n",
    "    for n,mod in enumerate(models):\n",
    "        for met in metrics: # import metric scores, number 1, 2\n",
    "            corr_dat['%i_%s'%(n+1,met)] = [dictout[mod].loc['pred']['%s_%s' % (pt,met)] for pt in pts]\n",
    "    \n",
    "    plt.figure(figsize=(8*len(models),8))\n",
    "    corr_list = {}\n",
    "    for clinVar in subscores:\n",
    "        corr_list[clinVar] = [] # create per subscore list of two corr's per model in models-list\n",
    "        for n,mod in enumerate(models):\n",
    "            for met in metrics:\n",
    "                r,p = spearmanr(corr_dat[clinVar], corr_dat['%i_%s'%(n+1,met)]) # calculate corr\n",
    "                corr_list[clinVar].append(r) # add r-value to list per subscore\n",
    "\n",
    "    xgroups = []\n",
    "    for modlab in mod_labels:\n",
    "        xgroups.extend(['%s\\nAUROC'%modlab,'%s\\nAccuracy'%modlab])\n",
    "    x = np.arange(len(xgroups))\n",
    "    width = 0.1\n",
    "    lw = 0.2\n",
    "    cs = 10\n",
    "    for n,clinVar in enumerate(subscores):\n",
    "        plt.bar(x+ 0.1*n, corr_list[clinVar], label=subscorelabels[n],  \n",
    "                capsize=cs,linewidth=lw, width=width, )#color='green' , yerr=stdsOFF, \n",
    "\n",
    "    plt.ylabel('Spearman Correlation R', size=24)\n",
    "    plt.title('Clinical MDS-UPDRS III subscores vs. Predictive performance with activity filtering', size=28)\n",
    "\n",
    "    plt.xticks(np.arange(0.3,len(xgroups)+.3,1),xgroups, rotation = 45, fontsize =24)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.ylim(-.5,0.5)\n",
    "    plt.legend(loc='lower center',ncol=4,prop={'size': 24})\n",
    "    plt.rcParams[\"axes.grid\"] = False\n",
    "    for h in np.arange(-0.3,0.5,0.1):\n",
    "        plt.axhline(y=h, zorder=0, color='lightgray')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(path,'figures','%s.png' % save_filename), dpi=300)\n",
    "\n",
    "    plt.show()       \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper FIG5\n",
    "# plot_clin_corr(['indiv_SV_allfts_actfilter','group_SV_allfts_actfilter'],\n",
    "#                ['Individual SV','Group SV'],\n",
    "#                True,'subscores_vs_performance_SVs_filtered')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## SUPPL FIG 6 (pm adjust title in function for w or w/o filter)\n",
    "# plot_clin_corr(['indiv_SV_allfts_actfilter','indiv_RF_allfts_actfilter',\n",
    "#  'group_SV_allfts_actfilter','group_RF_allfts_actfilter'],\n",
    "# ['Individual SV','Individual RF',\n",
    "#  'Group SV','Group RF'],\n",
    "#              True,'subscores_vs_performance_actfilter')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Visualizing effect of different number of trainings patients on group model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_pts(actfilter,save):\n",
    "    fig,ax=plt.subplots(1,1,figsize=(16,8))\n",
    "    colors=['purple','orange']\n",
    "    lstyles=['-','--']\n",
    "    for c,cls in enumerate(['SV','RF']):\n",
    "        if actfilter:\n",
    "            dat=pd.read_csv(os.path.join(path,'results','preds_%s_nr_train_pts_actfilter.csv'%cls), index_col=0)\n",
    "        else:\n",
    "            dat=pd.read_csv(os.path.join(path,'results','preds_%s_nr_train_pts.csv'%cls), index_col=0)\n",
    "        scores = pd.DataFrame(index=np.arange(1,20), columns=['AUROC','AUROC_sd','Accuracy','Accuracy_sd'])\n",
    "        for n_pts in scores.index:\n",
    "            for met in ['AUROC','Accuracy']:\n",
    "                scores.at[n_pts,met] = np.mean(dat['%s_mean_n%i'%(met,n_pts)]) # mean and std's over tested patients\n",
    "                scores.at[n_pts,met+'_sd'] = np.std(dat['%s_mean_n%i'%(met,n_pts)])\n",
    "        for m,met in enumerate(['AUROC','Accuracy']):\n",
    "            x_plot = scores.index\n",
    "            ax.plot(x_plot, scores[met], label='Mean %s (%s)' % (met,cls), linestyle=lstyles[m],\n",
    "                    c=colors[c], lw=2)\n",
    "#             high = np.array(scores[met]-scores['%s_sd' %met]).astype(float)\n",
    "#             low = np.array(scores[met]+scores['%s_sd' %met]).astype(float)\n",
    "#             ax.fill_between(x_plot, low,high, color= colors[m], alpha=0.1, label='Std dev %s'%met)\n",
    "    # config figure\n",
    "    ax.legend(fontsize=20)\n",
    "    ax.set_xlabel('Number of patients used for training', fontsize=20)\n",
    "    ax.set_xticks(np.arange(1,20,2))\n",
    "    ax.tick_params(labelsize=20)\n",
    "    ax.grid(True, axis='both', which='major')\n",
    "    if actfilter:\n",
    "        ax.set_title('Effect of number of training patients in group models, with activity filter', fontsize=24)\n",
    "    else:\n",
    "        ax.set_title('Effect of number of training patients in group models', fontsize=24)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        if actfilter: \n",
    "            plt.savefig(os.path.join(path,'figures','Effect_numTrainingPtsGroupModels_actfilter.png'), dpi=300)\n",
    "        else:\n",
    "            plt.savefig(os.path.join(path,'figures','Effect_numTrainingPtsGroupModels.png'), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_training_pts(actfilter=False,save=True)\n",
    "# plot_training_pts(actfilter=True,save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
